# ThesisFlow-AI

*Comprehensive AI-powered research platform for academic discovery, document processing, and team collaboration*

[![License](https://img.shields.io/badge/License-MIT-FF6B2C?style=flat-square)](https://github.com/Kedhareswer/thesisflow-ai/blob/unified/LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/Kedhareswer/thesisflow-ai?style=flat-square&color=FF6B2C)](https://github.com/Kedhareswer/thesisflow-ai)
[![Production](https://img.shields.io/badge/Status-Production_Ready-28a745?style=flat-square)](https://thesisflow-ai.vercel.app)
[![Version](https://img.shields.io/badge/Version-2.1.0-FF6B2C?style=flat-square)](https://github.com/Kedhareswer/thesisflow-ai)

## ğŸš€ Core Features

| ğŸ” Explorer | âœï¸ Writer | ğŸ“… Planner | ğŸ‘¥ Collaborate |
|-------------|-----------|-------------|----------------|
| **Multi-source literature search**<br/>â€¢ 11+ academic databases<br/>â€¢ AI research assistant with streaming<br/>â€¢ Deep research with real-time results<br/>â€¢ Citation analysis & export | **LaTeX collaborative editor**<br/>â€¢ Real-time preview with KaTeX<br/>â€¢ Multi-format document extraction<br/>â€¢ AI writing assistance<br/>â€¢ OCR for images & scanned docs | **AI-powered project management**<br/>â€¢ Intelligent task generation<br/>â€¢ Gantt charts & calendar views<br/>â€¢ Team assignments & tracking<br/>â€¢ Progress analytics | **Real-time team collaboration**<br/>â€¢ WebSocket-powered chat<br/>â€¢ File sharing & mentions<br/>â€¢ Presence indicators<br/>â€¢ Role-based permissions |

## ğŸ› ï¸ Tech Stack

```mermaid
graph TB
    subgraph "Frontend Architecture"
        A[Next.js 15 + React 19] --> B[TypeScript + TailwindCSS]
        B --> C[Shadcn/UI + Framer Motion]
        C --> D[KaTeX + Tesseract.js]
    end
    
    subgraph "Backend Services"
        E[Supabase PostgreSQL] --> F[Row Level Security]
        G[WebSocket Server] --> H[Socket.IO + JWT Auth]
        I[Server-Sent Events] --> J[AI Streaming]
    end
    
    subgraph "AI Provider Ecosystem"
        K[OpenAI GPT-4o/o3/o3-mini] --> L[Multi-Provider Router]
        M[Google Gemini 2.5 Pro/Flash] --> L
        N[Anthropic Claude 4.1/3.5] --> L
        O[Groq LLaMA 3.3-70B] --> L
        P[Mistral Large 2411] --> L
        Q[AIML Cross-Provider API] --> L
    end
    
    subgraph "Document Processing"
        R[PDF Parser] --> S[Extraction Engine]
        T[Mammoth.js DOCX] --> S
        U[Tesseract.js OCR] --> S
        V[PapaCSV Parser] --> S
    end
    
    subgraph "Literature APIs"
        W[OpenAlex] --> X[Search Orchestrator]
        Y[arXiv + CrossRef] --> X
        Z[Google Scholar] --> X
        AA[PubMed + DOAJ] --> X
    end
    
    A --> E
    A --> I
    L --> J
    S --> E
    X --> E
    
    style A fill:#FF6B2C,color:#fff
    style E fill:#FF6B2C,color:#fff
    style L fill:#FF6B2C,color:#fff
    style S fill:#28a745,color:#fff
    style X fill:#17a2b8,color:#fff
```

## âš¡ Quick Start

```bash
# 1. Clone and setup
git clone https://github.com/Kedhareswer/thesisflow-ai.git
cd thesisflow-ai
pnpm install

# 2. Configure environment
cp env.template .env.local
# Edit .env.local with your API keys (see setup guide below)

# 3. Start development servers
pnpm dev                         # Frontend (port 3000)
node server/websocket-server.js  # WebSocket collaboration (port 3001)

# 4. Optional: Python literature search service
cd python && python app.py      # Enhanced search APIs (port 5000)
```

### ğŸ”§ Required Configuration

**Essential Services:**
- **Supabase**: Database, authentication, file storage, and RLS policies
- **AI Provider**: At least one from OpenAI, Gemini, Claude, Groq, Mistral, or AIML
- **HuggingFace**: For AI content detection and model inference

**Enhanced Features:**
- **Google Search API**: Advanced literature search and citation discovery
- **Stripe**: Subscription management and payment processing  
- **Academic APIs**: Unpaywall, CORE, SerpAPI for comprehensive research

**ğŸŒ Live Demo:** [thesisflow-ai.vercel.app](https://thesisflow-ai.vercel.app)

---

## ğŸ’ Monthly Token System

ThesisFlow-AI uses an intelligent monthly token system that powers all AI features:

| Plan | Monthly Tokens | Features | Price |
|------|----------------|----------|-------|
| **Free** | 50 tokens | Core research tools, basic AI assistance | $0 |
| **Pro** | 500 tokens | Advanced AI models, priority processing, collaboration | $19/month |

### ğŸ”¥ Token Usage

**AI-Powered Features (Token Required):**
- ğŸ¤– AI Chat & Research Assistant (streaming responses)
- ğŸ” Topic Exploration & Deep Research
- ğŸ“„ Document Summarization & Analysis
- ğŸ“‹ AI Project Planning & Task Generation
- âœï¸ LaTeX Writing Assistance

**Always Free Features:**
- ğŸ“š Literature Search (11+ academic databases)
- ğŸ“Š Project Management & Calendar
- ğŸ‘¥ Team Collaboration & Chat
- ğŸ“ File Upload & Document Extraction
- ğŸ“ˆ Analytics & Progress Tracking

### ğŸ“Š Usage Monitoring

Track your token consumption across the platform:
- **Navigation Bar**: Live token counter with usage breakdown
- **Profile Menu**: Current plan status and upgrade options
- **Plan & Analytics** (`/plan`): Detailed usage charts by feature
- **Token Dashboard** (`/tokens`): Transaction history and cost analysis

*Tokens reset monthly and unused tokens don't roll over. Upgrade anytime for immediate access to additional tokens.*

## ğŸ“‹ Changelog

Stay up to date with the latest releases and improvements:

- **Web**: https://thesisflow-ai.vercel.app/changelog
- **RSS**: https://thesisflow-ai.vercel.app/changelog/rss.xml
- **Atom**: https://thesisflow-ai.vercel.app/changelog/atom.xml

Direct links to specific versions: `https://thesisflow-ai.vercel.app/changelog#v2.1.0`

---

## ğŸ¯ Advanced Features

### ğŸ” Literature Explorer & Deep Research

```mermaid
flowchart TB
    A[Research Query] --> B[Unified Search Orchestrator]
    
    subgraph "Academic Databases"
        C[OpenAlex - 250M+ papers]
        D[arXiv - Preprints]
        E[CrossRef - DOI Registry]
        F[PubMed - Medical Literature]
        G[DOAJ - Open Access]
        H[OpenAIRE - European Research]
    end
    
    subgraph "Web & News Sources"
        I[Google Scholar]
        J[DuckDuckGo Search]
        K[Tavily AI Search]
        L[Context7 Documentation]
        M[LangSearch Multi-Source]
    end
    
    subgraph "AI Processing Pipeline"
        N[Real-time Streaming Results]
        O[Smart Deduplication]
        P[Citation Analysis & Ranking]
        Q[AI Research Assistant]
    end
    
    B --> C & D & E & F & G & H
    B --> I & J & K & L & M
    C & D & E & F & G & H --> N
    I & J & K & L & M --> N
    N --> O --> P --> Q
    
    Q --> R[Streaming Chat Interface]
    Q --> S[Export & Citation Tools]
    Q --> T[Topic Deep Dive]
    
    style B fill:#FF6B2C,color:#fff
    style N fill:#17a2b8,color:#fff
    style Q fill:#28a745,color:#fff
```

**ğŸš€ Next-Generation Search Capabilities:**

| Feature | Technology | Performance | Benefits |
|---------|------------|-------------|----------|
| **Multi-Source Search** | 11+ APIs with intelligent orchestration | 1-3s response time | Comprehensive coverage, no missed papers |
| **Real-time Streaming** | Server-Sent Events + WebSocket | <100ms latency | Live results as they arrive |
| **AI Research Assistant** | GPT-4o/Claude/Gemini with conversation memory | 3-8s generation | Context-aware answers with citations |
| **Smart Caching** | Supabase + Redis with 1-hour TTL | 85%+ cache hit rate | Instant results for repeated queries |
| **Citation Analysis** | OpenAlex graph traversal | Forward/backward links | Discover influential and related work |
| **Export Integration** | BibTeX, RIS, JSON, CSV formats | Bulk export support | Seamless reference management |

### âœï¸ LaTeX Writer & Document Processing

```mermaid
flowchart TB
    subgraph "Multi-Format Document Processing"
        A[File Upload - 10MB Max] --> B[Format Detection Engine]
        B --> C{Processing Pipeline}
        
        C -->|PDF| D[pdf-parse + OCR<br/>Text, Tables, Images]
        C -->|DOCX/DOC| E[mammoth.js<br/>Rich Text + Media]
        C -->|PowerPoint| F[XML Parser<br/>Slides + Notes + Metadata]
        C -->|CSV/Excel| G[PapaCSV + XLSX<br/>Data Analysis]
        C -->|Images/Scans| H[Tesseract.js + Sharp<br/>OCR + Image Processing]
        C -->|Plain Text| I[Direct Text Analysis<br/>NLP + Structure]
        
        D & E & F & G & H & I --> J[Extraction Orchestrator]
        J --> K[AI Analysis Engine]
        K --> L[Structured Output]
    end
    
    subgraph "Collaborative LaTeX Editor"
        M[LaTeX Editor Interface] --> N[Real-time Preview]
        N --> O[KaTeX Math Rendering]
        O --> P[Live Formula Display]
        
        M --> Q[Multi-User Collaboration]
        Q --> R[Presence Indicators]
        Q --> S[Real-time Sync]
        Q --> T[Conflict Resolution]
        
        M --> U[Smart LaTeX Toolbar]
        U --> V[Document Structure]
        U --> W[Math & Equations]
        U --> X[Citations & References]
        U --> Y[Tables & Figures]
    end
    
    L --> Z[AI Writing Assistant]
    Z --> AA[LaTeX Content Generation]
    AA --> M
    
    style J fill:#FF6B2C,color:#fff
    style M fill:#28a745,color:#fff
    style Z fill:#17a2b8,color:#fff
```

**ğŸ”§ Advanced Document Processing:**

| Format | Extraction Capabilities | Processing Speed | AI Enhancement |
|--------|------------------------|------------------|----------------|
| **PDF** | Text, tables, images, metadata, OCR for scanned docs | 15-45s | Structure analysis, key insights, citations |
| **DOCX/DOC** | Rich text, tables, images, comments, track changes | 10-30s | Content summarization, formatting preservation |
| **PowerPoint** | Slides, speaker notes, embedded media, animations | 20-40s | Presentation flow analysis, key points extraction |
| **CSV/Excel** | Data parsing, type detection, statistical analysis | 5-15s | Data insights, trend analysis, visualization suggestions |
| **Images/Scans** | OCR text extraction, layout analysis, metadata | 30-90s | Content recognition, text structure, quality enhancement |
| **Plain Text** | Direct processing, encoding detection, structure | 2-10s | NLP analysis, topic modeling, sentiment analysis |

**ğŸ¨ LaTeX Editor Features:**

- **Real-time Collaboration**: Multi-user editing with live cursors and presence
- **Live Preview**: Split-pane with instant KaTeX mathematical rendering
- **Smart Toolbar**: LaTeX-specific commands, shortcuts, and templates
- **AI Integration**: Generate LaTeX content from natural language prompts
- **Export Options**: PDF compilation, LaTeX source, HTML preview
- **Template Library**: Academic papers, theses, presentations, and custom templates
- **Citation Management**: BibTeX integration with automatic formatting
- **Version Control**: Document history, branching, and merge capabilities

### ğŸ“… AI-Powered Project Management

```mermaid
flowchart TB
    subgraph "AI Planning Engine"
        A[Natural Language Input] --> B[AI Task Generator]
        B --> C[Smart Scheduling]
        C --> D[Dependency Analysis]
        D --> E[Resource Allocation]
    end
    
    subgraph "Project Visualization"
        F[Interactive Calendar] --> G[Gantt Charts]
        G --> H[Kanban Boards]
        H --> I[Progress Analytics]
        I --> J[Timeline Views]
    end
    
    subgraph "Team Collaboration"
        K[Role-based Access] --> L[Task Assignments]
        L --> M[Real-time Updates]
        M --> N[Notification System]
        N --> O[Progress Tracking]
    end
    
    subgraph "Data & Intelligence"
        P[Supabase Backend] --> Q[RLS Security]
        Q --> R[Usage Analytics]
        R --> S[Performance Insights]
        S --> T[Predictive Scheduling]
    end
    
    E --> F
    J --> K
    O --> P
    T --> A
    
    style B fill:#FF6B2C,color:#fff
    style F fill:#28a745,color:#fff
    style K fill:#17a2b8,color:#fff
    style P fill:#6f42c1,color:#fff
```

**ğŸ¤– Intelligent Planning Features:**

| Feature | AI Technology | Capabilities | Benefits |
|---------|---------------|--------------|----------|
| **AI Task Generation** | GPT-4o + Planning Prompts | Natural language â†’ structured tasks | 10x faster project setup |
| **Smart Scheduling** | Constraint optimization | Automatic dependency resolution | Conflict-free timelines |
| **Progress Prediction** | ML analytics on completion patterns | Deadline risk assessment | Proactive project management |
| **Resource Optimization** | Team capacity analysis | Workload balancing | Improved productivity |

**ğŸ“Š Multi-View Project Management:**
- **Calendar Integration**: Date-fns powered scheduling with conflict detection
- **Gantt Charts**: Interactive timeline visualization with drag-drop editing
- **Kanban Boards**: Agile workflow management with custom columns
- **Analytics Dashboard**: Completion rates, velocity tracking, team performance
- **Hierarchical Structure**: Projects â†’ Tasks â†’ Subtasks â†’ Comments with full nesting
- **Real-time Sync**: Live updates across all team members and devices

### ğŸ‘¥ Real-time Team Collaboration

```mermaid
flowchart TB
    subgraph "WebSocket Infrastructure"
        A[Socket.IO Server - Port 3001] --> B[JWT Authentication]
        B --> C[Team Rooms & Channels]
        C --> D[Message Broadcasting]
        D --> E[Presence Management]
    end
    
    subgraph "Communication Features"
        F[Real-time Chat] --> G[File Sharing & Attachments]
        G --> H[@Mentions & Notifications]
        H --> I[Typing Indicators]
        I --> J[Read Receipts & Status]
        J --> K[Message Threading]
    end
    
    subgraph "Collaboration Tools"
        L[Document Co-editing] --> M[Live Cursors]
        M --> N[Change Tracking]
        N --> O[Conflict Resolution]
        O --> P[Version History]
    end
    
    subgraph "Team Management"
        Q[Role-based Permissions] --> R[Owner/Admin/Editor/Viewer]
        R --> S[Granular Access Control]
        S --> T[Notification Preferences]
        T --> U[Email & Push Integration]
    end
    
    A --> F & L & Q
    K --> V[Multi-device Sync]
    P --> W[Backup & Recovery]
    U --> X[Cross-platform Notifications]
    
    style A fill:#FF6B2C,color:#fff
    style F fill:#28a745,color:#fff
    style L fill:#17a2b8,color:#fff
    style Q fill:#6f42c1,color:#fff
```

**ğŸš€ Advanced Collaboration Capabilities:**

| Feature | Technology Stack | Performance | Capabilities |
|---------|------------------|-------------|--------------|
| **Real-time Messaging** | Socket.IO + PostgreSQL + RLS | <50ms latency | Instant delivery, persistence, search |
| **Document Collaboration** | WebSocket + Operational Transform | Live sync | Multi-user editing, conflict resolution |
| **Presence System** | In-memory + Database hybrid | Real-time updates | Online status, activity tracking, typing |
| **File Management** | Supabase Storage + CDN | Secure uploads | Version control, sharing permissions |
| **Notification Engine** | WebSocket + Email + Push | Multi-channel | Granular preferences, smart batching |
| **Team Administration** | RLS + JWT + Role Engine | Enterprise-grade | Fine-grained permissions, audit trails |

**ğŸ” Enterprise Security:**
- **End-to-end Encryption**: All messages and files encrypted in transit and at rest
- **Row Level Security**: Database-level access control with Supabase RLS
- **JWT Authentication**: Secure token-based authentication with refresh tokens
- **Audit Logging**: Complete activity tracking for compliance and security
- **GDPR Compliance**: Data privacy controls and user data portability

### ğŸ¤– Advanced AI Integration

```mermaid
flowchart TB
    subgraph "Multi-Provider AI Router"
        A[Intelligent Provider Selection] --> B[OpenRouter Integration]
        B --> C[Fallback Chain Management]
        C --> D[Token & Cost Optimization]
        D --> E[Usage Analytics]
    end
    
    subgraph "AI Provider Ecosystem"
        F[OpenAI GPT-4o/o3/o3-mini]
        G[Google Gemini 2.5 Pro/Flash]
        H[Anthropic Claude 4.1/3.5 Sonnet]
        I[Groq LLaMA 3.3-70B Versatile]
        J[Mistral Large 2411/Codestral]
        K[AIML Cross-Provider API]
        L[OpenRouter Free Tier Models]
    end
    
    subgraph "Streaming Infrastructure"
        M[Server-Sent Events] --> N[Real-time Token Streaming]
        N --> O[Progress Tracking & Reasoning]
        O --> P[Heartbeat & Connection Management]
        P --> Q[Graceful Error Handling]
    end
    
    subgraph "AI-Powered Features"
        R[Conversational Research Assistant]
        S[LaTeX Content Generation]
        T[Document Analysis & Extraction]
        U[Project Planning & Task Generation]
        V[Literature Summarization]
        W[Citation & Reference Management]
    end
    
    A --> F & G & H & I & J & K & L
    F & G & H & I & J & K & L --> M
    M --> R & S & T & U & V & W
    
    style A fill:#FF6B2C,color:#fff
    style M fill:#28a745,color:#fff
    style R fill:#17a2b8,color:#fff
```

**ğŸš€ Next-Generation AI Capabilities:**

| Provider | Latest Models | Context Window | Specialized Features | Primary Use Cases |
|----------|---------------|----------------|---------------------|------------------|
| **OpenAI** | GPT-4o, o3, o3-mini | 200K tokens | Advanced reasoning, function calling | Complex analysis, research synthesis |
| **Google Gemini** | 2.5 Pro/Flash, 2.0 Flash | 1M tokens | Ultra-long context, multimodal | Document processing, comprehensive analysis |
| **Anthropic** | Claude 4.1 Opus, 3.5 Sonnet | 200K tokens | Academic writing, ethical reasoning | Research papers, literature reviews |
| **Groq** | LLaMA 3.3-70B, Whisper | 128K tokens | Ultra-fast inference (500+ tok/s) | Real-time chat, quick responses |
| **Mistral** | Large 2411, Codestral | 128K tokens | Code generation, multilingual | Technical writing, programming |
| **AIML API** | Cross-provider access | Variable | Model aggregation, cost optimization | Fallback routing, budget management |

**ğŸ”¥ Advanced AI Features:**

- **Streaming Conversations**: Real-time token-by-token responses with progress tracking
- **Context Preservation**: Full conversation history maintained across sessions
- **Intelligent Fallbacks**: Automatic provider switching on failures or rate limits
- **Reasoning Display**: Live AI thinking process visualization during complex tasks
- **Multi-Modal Processing**: Text, images, documents, and data analysis
- **Cost Optimization**: Smart model selection based on task complexity and budget
- **OpenRouter Integration**: Access to 100+ models through unified API

---

## ğŸ—ï¸ System Architecture

### Complete Platform Overview

```mermaid
flowchart TB
    subgraph "Frontend Layer"
        A[Next.js 15 + React 19] --> B[TypeScript + TailwindCSS]
        B --> C[Shadcn/UI + Framer Motion]
        C --> D[KaTeX + Tesseract.js]
    end
    
    subgraph "API Gateway & Routes"
        E[AI Streaming Routes] --> F[SSE + WebSocket]
        G[Literature Search APIs] --> H[Multi-Source Orchestration]
        I[Document Processing] --> J[Extraction Pipeline]
        K[Collaboration APIs] --> L[Real-time Messaging]
        M[Project Management] --> N[Planning & Analytics]
    end
    
    subgraph "Real-time Infrastructure"
        O[Socket.IO Server - Port 3001] --> P[JWT Authentication]
        Q[Server-Sent Events] --> R[AI Token Streaming]
        S[Keep-alive Services] --> T[Cloud Platform Support]
        U[WebSocket Rooms] --> V[Team Collaboration]
    end
    
    subgraph "Database & Storage Layer"
        W[Supabase PostgreSQL] --> X[Row Level Security]
        Y[File Storage + CDN] --> Z[Document Management]
        AA[Authentication Service] --> BB[JWT + Session Management]
        CC[Caching Layer] --> DD[Redis + Memory Cache]
    end
    
    subgraph "AI & External Services"
        EE[Multi-Provider AI Router] --> FF[OpenAI + Gemini + Claude + Groq + Mistral + AIML]
        GG[Literature Search Engine] --> HH[OpenAlex + arXiv + CrossRef + PubMed + DOAJ + Google Scholar]
        II[Document Processing Engine] --> JJ[PDF + DOCX + PPT + CSV + OCR + Text Analysis]
        KK[OpenRouter Integration] --> LL[100+ Free & Premium Models]
    end
    
    A --> E & G & I & K & M
    E --> EE
    G --> GG
    I --> II
    K --> O
    M --> W
    O --> W
    EE --> FF
    GG --> HH
    II --> JJ
    KK --> FF
    
    style A fill:#FF6B2C,color:#fff
    style W fill:#28a745,color:#fff
    style EE fill:#17a2b8,color:#fff
    style O fill:#6f42c1,color:#fff
    style GG fill:#ffc107,color:#000
```

### ğŸ”§ Core Architecture Components

| Layer | Technology Stack | Purpose | Performance |
|-------|------------------|---------|-------------|
| **Frontend** | Next.js 15, React 19, TypeScript, TailwindCSS | Modern UI with server-side rendering | <100ms page loads |
| **Database** | Supabase PostgreSQL with RLS | Secure data storage and real-time sync | 99.9% uptime |
| **AI Services** | Multi-provider router with OpenRouter | Intelligent content generation | 3-8s response time |
| **Real-time** | Socket.IO + WebSocket infrastructure | Live collaboration and messaging | <50ms latency |
| **Document Processing** | Multi-format extraction pipeline | File analysis and OCR | 15-45s processing |
| **Literature Search** | 11+ academic database integration | Comprehensive research discovery | 1-3s search time |

### ğŸ›¡ï¸ Security & Performance

**ğŸ”’ Enterprise-Grade Security:**
- **Authentication**: JWT-based auth with Supabase and refresh token rotation
- **Authorization**: Row Level Security (RLS) policies with fine-grained permissions
- **Data Protection**: End-to-end encryption for files and messages
- **API Security**: Rate limiting, request validation, and CORS protection
- **Compliance**: GDPR-ready with data portability and deletion controls

**âš¡ Performance Benchmarks:**

| Feature | Response Time | Throughput | Reliability | Scalability |
|---------|---------------|------------|-------------|-------------|
| **Literature Search** | 1-3s | 100+ req/min | 98% success rate | 50+ concurrent users |
| **AI Generation** | 3-8s streaming | 30+ concurrent | 95% success rate | Auto-scaling |
| **Document Processing** | 15-45s | 25+ files/min | 92% success rate | Queue-based |
| **Real-time Chat** | <50ms | 1000+ msg/min | 99.9% uptime | 500+ concurrent |
| **File Upload** | 2-10s | 20MB/file | 96% success rate | CDN-accelerated |

---

## ğŸš€ Complete Setup Guide

### ğŸ“‹ Prerequisites

| Requirement | Version | Purpose | Installation |
|-------------|---------|---------|--------------|
| **Node.js** | 18.0+ | Frontend runtime | [nodejs.org](https://nodejs.org/) |
| **pnpm** | Latest | Fast package manager | `npm install -g pnpm` |
| **Python** | 3.8+ | Optional backend services | [python.org](https://python.org/) |
| **Supabase Account** | - | Database & authentication | [supabase.com](https://supabase.com/) |
| **AI Provider Account** | - | At least one AI service | See provider links below |

### ğŸ› ï¸ Installation Steps

```bash
# 1. Clone repository and install dependencies
git clone https://github.com/Kedhareswer/thesisflow-ai.git
cd thesisflow-ai
pnpm install

# 2. Configure environment variables
cp env.template .env.local
# Edit .env.local with your API keys (see configuration guide below)

# 3. Start development servers
pnpm dev                         # Frontend (port 3000)
node server/websocket-server.js  # WebSocket collaboration (port 3001)

# 4. Optional: Python literature search service
cd python
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python app.py                    # Literature APIs (port 5000)
```

### ğŸ”‘ Environment Configuration

**Step 1: Create Supabase Project**
1. Visit [supabase.com](https://supabase.com/) and create a new project
2. Go to Settings â†’ API to get your project URL and keys
3. Run the database setup scripts in `scripts/` folder

**Step 2: Get AI Provider API Keys**
Choose at least one AI provider:

| Provider | Get API Key | Models Available | Cost |
|----------|-------------|------------------|------|
| **OpenAI** | [platform.openai.com](https://platform.openai.com/api-keys) | GPT-4o, o3, o3-mini | $0.01-0.06/1K tokens |
| **Google Gemini** | [makersuite.google.com](https://makersuite.google.com/app/apikey) | Gemini 2.5 Pro/Flash | $0.001-0.01/1K tokens |
| **Anthropic** | [console.anthropic.com](https://console.anthropic.com/settings/keys) | Claude 4.1, 3.5 Sonnet | $0.003-0.015/1K tokens |
| **Groq** | [console.groq.com](https://console.groq.com/keys) | LLaMA 3.3-70B | Free tier available |
| **Mistral** | [console.mistral.ai](https://console.mistral.ai/api-keys/) | Large 2411, Codestral | $0.002-0.008/1K tokens |

**Step 3: Configure .env.local**

Copy the essential variables to your `.env.local` file:

```bash
# Supabase Configuration (Required)
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# AI Provider (Choose at least one)
OPENAI_API_KEY=your_openai_api_key
GEMINI_API_KEY=your_gemini_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GROQ_API_KEY=your_groq_api_key
MISTRAL_API_KEY=your_mistral_api_key

# HuggingFace (Required for AI content detection)
HUGGINGFACE_API_KEY=your_huggingface_api_key

# WebSocket Configuration
NEXT_PUBLIC_SOCKET_URL=http://localhost:3001

# Optional: Enhanced Features
GOOGLE_SEARCH_API_KEY=your_google_search_api_key
GOOGLE_SEARCH_CSE_ID=your_custom_search_engine_id
STRIPE_SECRET_KEY=your_stripe_secret_key
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=your_stripe_publishable_key
```

### ğŸ”’ Security Best Practices

| Security Measure | Implementation | Importance |
|------------------|----------------|------------|
| **Environment Isolation** | Separate `.env.local` for dev/prod | Critical |
| **API Key Rotation** | Monthly key rotation schedule | High |
| **Usage Monitoring** | Track API consumption and costs | High |
| **Access Control** | RLS policies and JWT validation | Critical |
| **Rate Limiting** | Per-user and per-endpoint limits | Medium |
| **Audit Logging** | Track all sensitive operations | Medium |

**ğŸš¨ Never commit `.env.local` to version control!**

### ğŸ—„ï¸ Database Setup

```bash
# Run database migrations (creates all required tables and functions)
node scripts/run-migration.js

# Verify Supabase connection
npx supabase status

# Optional: Seed with sample data for development
node scripts/seed-database.js
```

**ğŸ“Š Database Schema Overview:**

| Table | Purpose | Key Features |
|-------|---------|--------------|
| `user_profiles` | User accounts and preferences | RLS policies, plan tracking |
| `projects` | Research projects and tasks | Hierarchical structure, team sharing |
| `teams` | Collaboration groups | Role-based permissions, invitations |
| `extractions` | Document processing results | File metadata, AI analysis |
| `chat_sessions` | AI conversation history | Context preservation, search |
| `literature_cache` | Search result caching | 1-hour TTL, deduplication |
| `user_tokens` | Monthly usage tracking | Token consumption, plan limits |

---

## ğŸ“¡ API Reference

### ğŸ”¥ Core API Endpoints

```http
# AI Services
GET  /api/ai/chat/stream          # Streaming AI chat with SSE
POST /api/ai/generate             # Single AI generation request
POST /api/ai-detect               # AI content detection

# Literature & Research
POST /api/literature-search/stream # Real-time literature search
GET  /api/search/papers           # Paper search with filters
POST /api/plan-and-execute        # AI project planning

# Document Processing
POST /api/extract                 # Multi-format document extraction
POST /api/extract/chat            # AI-powered document analysis
GET  /api/extractions/recent      # User's recent extractions

# Team Collaboration
GET  /api/collaborate/teams       # User's teams and permissions
POST /api/collaborate/messages    # Send team messages
WebSocket: ws://localhost:3001    # Real-time collaboration

# User Management
GET  /api/user/tokens             # Token usage and limits
PUT  /api/user/tokens/deduct      # Deduct tokens for AI features
GET  /api/user/plan               # Current subscription plan
```

### ğŸ” Authentication & Security

All API endpoints use Supabase JWT authentication with automatic RLS filtering:

```javascript
// Client-side API calls (tokens handled automatically)
const { data, error } = await supabase
  .from('projects')
  .select('*')
  // RLS automatically filters to user's projects

// Manual API calls with auth headers
const response = await fetch('/api/extract', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${session.access_token}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({ /* request data */ })
})
```

### âš¡ Rate Limits & Performance

| Feature | Rate Limit | Burst Capacity | Cache TTL |
|---------|------------|----------------|-----------|
| **AI Chat Streaming** | 50/hour | 5 concurrent | - |
| **Literature Search** | 100/hour | 10 concurrent | 1 hour |
| **Document Extraction** | 20/hour | 3 concurrent | 24 hours |
| **Team Collaboration** | 1000/hour | 50 concurrent | Real-time |
| **File Upload** | 20/hour | 10MB max | - |

---

## ğŸš€ Deployment & Production

### ğŸŒ Deployment Options

| Platform | Configuration | Benefits | Cost |
|----------|---------------|----------|------|
| **Vercel** | Zero-config Next.js deployment | Auto-scaling, CDN, preview deployments | $20/month |
| **Netlify** | Static site + serverless functions | Git-based deploys, form handling | $19/month |
| **Railway** | Full-stack deployment | Database included, simple setup | $5-20/month |
| **Google Cloud Run** | Containerized deployment | Pay-per-use, custom domains | Variable |

### ğŸ“Š Production Metrics

```mermaid
graph TB
    A[Performance Metrics] --> A1[API Response: <200ms]
    A --> A2[Search Speed: 1-3s]
    A --> A3[AI Generation: 3-8s]
    
    B[Reliability] --> B1[Uptime: 99.9%]
    B --> B2[Success Rate: 95%+]
    B --> B3[Error Recovery: <5s]
    
    C[Scalability] --> C1[Concurrent Users: 500+]
    C --> C2[Requests/min: 1000+]
    C --> C3[Storage: Unlimited]
    
    style A fill:#FF6B2C,color:#fff
    style B fill:#28a745,color:#fff
    style C fill:#17a2b8,color:#fff
```

---

## ğŸ¤ Contributing

We welcome contributions from the research community! 

### ğŸ› ï¸ Development Workflow

```bash
# 1. Fork and clone the repository
git clone https://github.com/your-username/thesisflow-ai.git
cd thesisflow-ai

# 2. Create a feature branch
git checkout -b feature/your-feature-name

# 3. Install dependencies and start development
pnpm install
pnpm dev

# 4. Make your changes and test thoroughly
pnpm lint
pnpm build

# 5. Submit a pull request with detailed description
```

### ğŸ“ Development Standards

- **TypeScript**: Strict mode with comprehensive type definitions
- **Code Quality**: ESLint + Prettier with automated formatting
- **Testing**: Unit tests for critical functions and API endpoints
- **Documentation**: JSDoc comments for all public functions
- **Security**: Never commit API keys or sensitive data

### ğŸ†˜ Getting Help

- **ğŸ“š Documentation**: [GitHub Wiki](https://github.com/Kedhareswer/thesisflow-ai/wiki)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/Kedhareswer/thesisflow-ai/discussions)
- **ğŸ› Bug Reports**: [GitHub Issues](https://github.com/Kedhareswer/thesisflow-ai/issues)
- **ğŸ“§ Direct Contact**: [support@thesisflow-ai.com](mailto:support@thesisflow-ai.com)

---

## ğŸ™ Acknowledgments

**ğŸ”§ Core Technologies:** Next.js 15 â€¢ React 19 â€¢ Supabase â€¢ TypeScript â€¢ TailwindCSS

**ğŸ¤– AI Partners:** OpenAI â€¢ Google â€¢ Anthropic â€¢ Groq â€¢ Mistral â€¢ HuggingFace

**ğŸ“š Academic Sources:** OpenAlex â€¢ arXiv â€¢ CrossRef â€¢ PubMed â€¢ Google Scholar

**ğŸ¨ UI Framework:** Shadcn/UI â€¢ Radix UI â€¢ Framer Motion â€¢ Lucide Icons

---

<div align="center">

**ğŸ“ Built with passion for the research community**

[![Live Demo](https://img.shields.io/badge/ğŸŒ_Live_Demo-thesisflow--ai.vercel.app-FF6B2C?style=for-the-badge)](https://thesisflow-ai.vercel.app)
[![Documentation](https://img.shields.io/badge/ğŸ“š_Documentation-GitHub_Wiki-28a745?style=for-the-badge)](https://github.com/Kedhareswer/thesisflow-ai/wiki)
[![Report Issues](https://img.shields.io/badge/ğŸ›_Report_Issues-GitHub-17a2b8?style=for-the-badge)](https://github.com/Kedhareswer/thesisflow-ai/issues)

**Status:** âœ… Production Ready â€¢ **Version:** 2.1.0 â€¢ **Updated:** January 2025

*Empowering researchers worldwide with AI-powered tools for discovery, collaboration, and innovation.*

</div>
